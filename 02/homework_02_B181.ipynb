{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework nr. 2 - data cleaning (deadline 8/11/2018)\n",
    "\n",
    "In short, the main task is to clean The Metropolitan Museum of Art Open Access dataset.\n",
    "  \n",
    "> The instructions are not given in details: It is up to you to come up with ideas on how to fulfill the particular tasks as best you can. ;)\n",
    "\n",
    "## What are you supposed to do:\n",
    "\n",
    "  1. Download the dataset MetObjects.csv from the repository https://github.com/metmuseum/openaccess/.\n",
    "  2. Check consistency of at least three features where you expect problems (include \"Object Name\" feature).\n",
    "  3. Select some features where you expect integrity problems (describe your choice) and check integrity of those features.\n",
    "  4. Convert at least five features to a proper data type. Choose at least one numeric, one categorical and one datetime.\n",
    "  5. Find some outliers (describe your selection criteria).\n",
    "  6. Detect missing data in at least three features, convert them to a proper representation (if they are already not), and impute missing values in at least one feature.\n",
    "\n",
    "**If you do all this properly, you will obtain 6 points**\n",
    "\n",
    "To earn **extra two points** you can do some of these:\n",
    "  * Focus more precisely on cleaning of the \"Medium\" feature. Such if you like to use it in KNN based algorithms later.\n",
    "  * Focus on the extraction of physical dimensions of each item (width, depth and height in centimeters) from the \"Dimensions\" feature.\n",
    "\n",
    "## Comments\n",
    "\n",
    "  * Please follow the instructions from https://courses.fit.cvut.cz/MI-PDD/homeworks/index.html.\n",
    "  * If the reviewing teacher is not satisfied, he can give you another chance to rework your homework and to obtain more points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('MetObjects.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check consistency of at least three features where you expect problems (include \"Object Name\" feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Object Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data['Object Name'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edited = data.copy()\n",
    "data_edited['Object Name'] = data_edited['Object Name'].str.replace('\\r\\n', ' ')\n",
    "data_edited['Object Name'] = data_edited['Object Name'].str.replace('\\(\\?\\)', ' ')\n",
    "data_edited['Object Name'] = data_edited['Object Name'].str.replace('\\?', ' ')\n",
    "data_edited['Object Name'] = data_edited['Object Name'].str.strip()\n",
    "data_edited['Object Name'] = data_edited['Object Name'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(data_edited['Object Name'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Artist Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before: '+str(len(data['Artist Role'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_to_set(input):\n",
    "    edited_input = str(input).strip()\n",
    "    edited_input = edited_input.replace(' and ','|')\n",
    "    edited_input = edited_input.replace(',','|')\n",
    "    edited_input = edited_input.lower()\n",
    "    edited_input = edited_input.strip()\n",
    "    roles = edited_input.split('|')\n",
    "    roles_set = set()\n",
    "    for role in roles:\n",
    "        roles_set.add(role)\n",
    "    roles_list = list(roles_set)\n",
    "    roles_list.sort()\n",
    "    return '|'.join(roles_list)\n",
    "    \n",
    "data_edited['Artist Role'] = data_edited['Artist Role'].apply(items_to_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After: '+str(len(data_edited['Artist Role'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Artist Nationality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before: '+str(len(data['Artist Nationality'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edited['Artist Nationality'] = data_edited['Artist Nationality'].apply(items_to_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After: '+str(len(data_edited['Artist Nationality'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select some features where you expect integrity problems (describe your choice) and check integrity of those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature: Excavation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(input):\n",
    "    dates = re.findall(r'\\d+', str(input))\n",
    "    dates_copy = dates.copy()\n",
    "    out = ''\n",
    "    if len(dates)==0:\n",
    "        return np.NaN\n",
    "    elif len(dates)==1:\n",
    "        return dates[0]\n",
    "    for i in range(len(dates)):\n",
    "        if i%2==1:\n",
    "            if len(dates[i])==2:\n",
    "                dates_copy[i]= dates_copy[i-1][0:2]+dates[i]\n",
    "            elif len(dates[i])==1:\n",
    "                dates_copy[i]= dates_copy[i-1][0:3]+dates[i]\n",
    "            \n",
    "        if i%2==1:\n",
    "            out +='-'\n",
    "            out +=dates_copy[i]\n",
    "            if not (i+1)== len(dates):\n",
    "                out+='|'\n",
    "        else:\n",
    "            out +=dates_copy[i]\n",
    "            \n",
    "    return out      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edited['Excavation date'] = data_edited['Excavation'].apply(get_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert at least five features to a proper data type. Choose at least one numeric, one categorical and one datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edited['Is Public Domain'] = data_edited['Is Public Domain'].astype('bool')\n",
    "data_edited['Is Highlight'] = data_edited['Is Highlight'].astype('bool')\n",
    "data_edited['Object ID'] = data_edited['Object ID'].astype('int64')\n",
    "department_cat = pd.api.types.CategoricalDtype(categories= data['Department'].unique(),ordered=False)\n",
    "data_edited['Department'] = data_edited['Department'].astype(department_cat)\n",
    "data_edited['Metadata Date'] =  pd.to_datetime(data_edited['Metadata Date'], format='%m/%d/%Y %I:%M:%S %p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find some outliers (describe your selection criteria)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR =  Q3 - Q1\n",
    "\n",
    "DateOut = (data['Object End Date'] > Q3['Object End Date'] + 2*IQR['Object End Date']) | (data['Object End Date'] < Q1['Object End Date'] - 2*IQR['Object End Date'])\n",
    "display(DateOut.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect missing data in at least three features, convert them to a proper representation (if they are already not), and impute missing values in at least one feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data in:\n",
    "*  Artist Prefix\n",
    "*  Geography Type\n",
    "*  Portfolio\n",
    "*  State\n",
    "\n",
    "There is no suitable feature, where can I impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edited['Artist Prefix'].replace(['?'], np.nan, inplace=True)\n",
    "data_edited['Artist Prefix'].replace([''], np.nan, inplace=True)\n",
    "\n",
    "data_edited['Geography Type'].replace(['|'], np.nan, inplace=True)\n",
    "data_edited['Geography Type'].replace(['||'], np.nan, inplace=True)\n",
    "\n",
    "data_edited['Portfolio'].replace(['\\r\\n'], np.nan, inplace=True)\n",
    "\n",
    "data_edited['State'].replace(['|'], np.nan, inplace=True)\n",
    "data_edited['State'].replace(['||'], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focus more precisely on cleaning of the \"Medium\" feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_edited['Medium'].replace(['\\r\\n'], np.nan, inplace=True)\n",
    "data_edited['Medium'] = data_edited['Medium'].str.replace('\\r\\n',' ')\n",
    "data_edited['Medium'] = data_edited['Medium'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensions cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dim(input):\n",
    "    numbers = re.findall('\\(.*?\\)',str(input))\n",
    "    out = []\n",
    "    for item in numbers:\n",
    "        unit = ''\n",
    "        subnumbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", str(item))\n",
    "        if len(subnumbers)==0:\n",
    "            continue\n",
    "        if 'cm' in item:\n",
    "            unit = 'cm'\n",
    "        elif 'g' in item:\n",
    "            unit = 'g'\n",
    "        for subnumber in subnumbers:\n",
    "            out.append(subnumber+unit)\n",
    "    if len(out)==0:\n",
    "        return np.nan\n",
    "    return '|'.join(out)\n",
    "    \n",
    "data_edited['Dimensions'] = data_edited['Dimensions'].str.replace('\\r\\n',' ')\n",
    "data_edited['Dimensions'].replace(['`'], np.nan, inplace=True)\n",
    "data_edited['Dimensions'].replace([''], np.nan, inplace=True)\n",
    "data_edited['Dimensions'] = data_edited['Dimensions'].str.strip()\n",
    "data_edited['Dimensions_cleaned'] = data_edited['Dimensions'].apply(process_dim)\n",
    "#data_edited['Dimensions_cleaned']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
